{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 61: Using COMPAS's CosmicIntegration to compute CHE merger rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nb_id is used to identify this notebook's output files (i.e., figures) if there are any\n",
    "# it should match \n",
    "# the first two digits in the notebook's title\n",
    "nb_id = 61"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.cm import ScalarMappable\n",
    "from matplotlib.colors import Normalize, TwoSlopeNorm, to_rgba\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "import astropy.units as u\n",
    "import astropy.constants as ct\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from src.util import Z_SUN, CODE_ROOT, DATA_ROOT\n",
    "\n",
    "from cosmic_integration.cosmology import get_cosmology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIGURE_FOLDER = Path(f'./output/nb{nb_id}/figures')\n",
    "FIGURE_FOLDER.mkdir(parents=True, exist_ok=True)\n",
    "plt.style.use('./plotstyle.mplstyle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Cosmic Integration functions (adapted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we load the interpolated populations for fixed metallicities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "guide_z_str = ['0.1', '0.2', '0.4', '0.6', '0.8', '1.0']\n",
    "guide_z_float = [float(z) for z in guide_z_str]\n",
    "\n",
    "res = int(1e6)\n",
    "\n",
    "def get_fname(id, size):\n",
    "    return f'{int(100*float(id)):03d}Zdiv100Zsun_enhanced_w_{size}_pop.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/home/ldesa/repos/cher/data/010Zdiv100Zsun_enhanced_w_1e+06_pop.npy found, loading.\n",
      "/mnt/home/ldesa/repos/cher/data/020Zdiv100Zsun_enhanced_w_1e+06_pop.npy found, loading.\n",
      "/mnt/home/ldesa/repos/cher/data/040Zdiv100Zsun_enhanced_w_1e+06_pop.npy found, loading.\n",
      "/mnt/home/ldesa/repos/cher/data/060Zdiv100Zsun_enhanced_w_1e+06_pop.npy found, loading.\n",
      "/mnt/home/ldesa/repos/cher/data/080Zdiv100Zsun_enhanced_w_1e+06_pop.npy found, loading.\n",
      "/mnt/home/ldesa/repos/cher/data/100Zdiv100Zsun_enhanced_w_1e+06_pop.npy found, loading.\n"
     ]
    }
   ],
   "source": [
    "pop_dict = dict()\n",
    "for z_str, z_float in zip(guide_z_str, guide_z_float):\n",
    "    fname = get_fname(z_str, f'{res:.0e}')\n",
    "    file = DATA_ROOT/fname\n",
    "    \n",
    "    if file.exists():\n",
    "        print(f'{file} found, loading.')\n",
    "        pop_dict[z_str] = np.load(file)\n",
    "    else:\n",
    "        print(f'{file} not found, ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In `pop_dict`, keys are $Z/\\mathrm{Z}_\\odot$, and each key holds a population of size `res` sampled at that metallicity as an array. For each array, columns are m_zams/Msun, p_zams/d, r_zam/Rsuns, m_bh/Msun, chi_bh, t_delay/yr."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now define an adapted version of a function from CosmicIntegration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "\n",
    "def find_formation_and_merger_rates(\n",
    "    n_binaries, \n",
    "    redshifts, \n",
    "    times,\n",
    "    time_first_SF,\n",
    "    n_formed,\n",
    "    dPdlogZ, \n",
    "    metallicities,\n",
    "    p_draw_metallicity,\n",
    "    COMPAS_metallicites,\n",
    "    COMPAS_delay_times, \n",
    "    COMPAS_weights=None\n",
    "    ):\n",
    "    \"\"\"\n",
    "        Find the formation and merger rates per binary per redshift\n",
    "\n",
    "        Args:\n",
    "            n_binaries          --> [int] Number of DCO binaries in the arrays\n",
    "            redshifts           --> [list of floats] Redshifts at which \n",
    "            to evaluate the rates\n",
    "            times               --> [list of floats] Equivalent of the \n",
    "            redshifts in terms of age of the Universe\n",
    "            n_formed            --> [float]          Binary formation \n",
    "            rate (number of binaries formed per year per cubic Gpc) \n",
    "            represented by each simulated COMPAS binary\n",
    "            dPdlogZ             --> [2D float array] Probability of \n",
    "            getting a particular logZ at a certain redshift\n",
    "            metallicities       --> [list of floats] Metallicities at \n",
    "            which dPdlogZ is evaluated; if this is None, assume that \n",
    "            metallicity weighting is 1 (corresponds to all SFR happening \n",
    "            at one fixed metallicity)\n",
    "            p_draw_metallicity  --> [float]          Probability of \n",
    "            drawing a certain metallicity in COMPAS (float because \n",
    "            assuming uniform)\n",
    "            COMPAS_metallicites --> [list of floats] Metallicity of each \n",
    "            binary in COMPAS data\n",
    "            COMPAS_delay_times  --> [list of floats] Delay time of each \n",
    "            binary in COMPAS data\n",
    "            COMPAS_weights      --> [list of floats] Adaptive sampling \n",
    "            weights for each binary in COMPAS data (defaults to all 1s \n",
    "            for unweighted samples)\n",
    "\n",
    "        Returns:\n",
    "            formation_rate      --> [2D float array] Formation rate for \n",
    "            each binary at each redshift\n",
    "            merger_rate         --> [2D float array] Merger rate for \n",
    "            each binary at each redshift\n",
    "    \"\"\"\n",
    "    \n",
    "    # check if weights were provided, if not use uniform weights\n",
    "    if COMPAS_weights is None:\n",
    "        COMPAS_weights = np.ones(n_binaries)\n",
    "\n",
    "    # initialise rates to zero\n",
    "    n_redshifts = len(redshifts)\n",
    "    redshift_step = redshifts[1] - redshifts[0]\n",
    "    formation_rate = np.zeros(shape=(n_binaries, n_redshifts))\n",
    "    merger_rate = np.zeros(shape=(n_binaries, n_redshifts))\n",
    "\n",
    "    # interpolate times and redshifts for conversion\n",
    "    times_to_redshifts = interp1d(times, redshifts)\n",
    "\n",
    "    # make note of the first time at which star formation occurred\n",
    "    age_first_sfr = time_first_SF\n",
    "\n",
    "    # go through each binary in the COMPAS data\n",
    "    for i in range(n_binaries):\n",
    "        # if metallicities array is None, assume all SFR happened at one \n",
    "        # fixed metallicity\n",
    "        if metallicities is None :\n",
    "            formation_rate[i, :] = n_formed * COMPAS_weights[i]\n",
    "        # calculate formation rate (see Neijssel+19 Section 4) - note \n",
    "        # this uses dPdlogZ for *closest* metallicity\n",
    "        else:\n",
    "            formation_rate[i, :] = (n_formed \n",
    "                                    * dPdlogZ[:, np.digitize(COMPAS_metallicites[i], metallicities)] \n",
    "                                    / p_draw_metallicity \n",
    "                                    * COMPAS_weights[i]\n",
    "                                    )\n",
    "\n",
    "        # calculate the time at which the binary formed if it merges at \n",
    "        # this redshift\n",
    "        time_of_formation = times - COMPAS_delay_times[i]\n",
    "\n",
    "        # we have only calculated formation rate up to z=max(redshifts),\n",
    "        # so we need to only find merger rates for formation times at \n",
    "        # z<max(redshifts) first locate the index above which the binary \n",
    "        # would have formed before z=max(redshifts)\n",
    "        first_too_early_index = np.digitize(age_first_sfr, time_of_formation)\n",
    "\n",
    "        # include the whole array if digitize returns end of array and \n",
    "        # subtract one so we don't include the time past the limit\n",
    "        first_too_early_index = (first_too_early_index + 1 \n",
    "                                 if first_too_early_index == n_redshifts \n",
    "                                 else first_too_early_index)\n",
    "\n",
    "        # as long as that doesn't preclude the whole range\n",
    "        if first_too_early_index > 0:\n",
    "            # work out the redshift at the time of formation\n",
    "            z_of_formation = times_to_redshifts(time_of_formation[:first_too_early_index - 1])\n",
    "\n",
    "            # calculate which index in the redshift array these \n",
    "            # edshifts correspond to\n",
    "            z_of_formation_index = np.ceil(z_of_formation / redshift_step).astype(int)\n",
    "\n",
    "            # set the merger rate at z (with z<10) to the formation rate\n",
    "            # at z_form\n",
    "            merger_rate[i, :first_too_early_index - 1] = formation_rate[i, z_of_formation_index]\n",
    "    return formation_rate, merger_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm as NormDist\n",
    "\n",
    "def find_metallicity_distribution(redshifts, min_logZ_COMPAS, max_logZ_COMPAS,\n",
    "                                  mu0=0.035, muz=-0.23, sigma_0=0.39, \n",
    "                                  sigma_z=0.0, alpha=0.0, min_logZ=-12.0, \n",
    "                                  max_logZ=0.0, step_logZ=0.01):\n",
    "    \"\"\"\n",
    "    Calculate the distribution of metallicities at different redshifts \n",
    "    using a log skew normal distribution. The log-normal distribution \n",
    "    is a special case of this log skew normal distribution and is \n",
    "    retrieved by setting the skewness to zero (alpha=0). Based on the \n",
    "    method in Neijssel+19. Default values retrieve the dP/dZ \n",
    "    distribution used in Neijssel+19. See van Son+2022 for skewed \n",
    "    log-normal distribution.\n",
    "\n",
    "    NOTE: This assumes that metallicities in COMPAS are drawn from a \n",
    "    flat-in-log distribution!\n",
    "\n",
    "    Args:\n",
    "        max_redshift       --> [float] Max redshift for calculation\n",
    "        redshift_step      --> [float] Step used in redshift calculation\n",
    "        min_logZ_COMPAS    --> [float] Min logZ value that COMPAS samples\n",
    "        max_logZ_COMPAS    --> [float] Max logZ value that COMPAS samples\n",
    "        mu0                --> [float] Location (mean in normal) at z=0\n",
    "        muz                --> [float] Redshift scaling of location\n",
    "        sigma_0            --> [float] Scale (variance in normal) at z=0\n",
    "        sigma_z            --> [float] Redshift scaling of the scale\n",
    "        alpha              --> [float] Shape (skewness, alpha=0 gives \n",
    "                                  normal dist as in Neijssel+19)\n",
    "        min_logZ           --> [float] Min logZ for dPdlogZ calculation\n",
    "        max_logZ           --> [float] Max logZ for dPdlogZ calculation\n",
    "        step_logZ          --> [float] Step size for logZ range\n",
    "\n",
    "    Returns:\n",
    "        dPdlogZ            --> [2D float array] Probability of getting a \n",
    "                                  particular logZ at a certain redshift\n",
    "        metallicities      --> [list of floats] Metallicities at which \n",
    "                                  dPdlogZ is evaluated\n",
    "        p_draw_metallicity --> [float] Probability of drawing a certain \n",
    "                                  metallicity in COMPAS\n",
    "    \"\"\"\n",
    "    # Log-linear redshift dependence of sigma\n",
    "    sigma = sigma_0 * 10**(sigma_z * redshifts)\n",
    "\n",
    "    # Mean metallicities evolve with redshift (Langer & Norman 2006)\n",
    "    mean_metallicities = mu0 * 10**(muz * redshifts)\n",
    "\n",
    "    # Rewrite expected value of log-skew-normal to retrieve mu\n",
    "    beta = alpha / (np.sqrt(1 + alpha**2))\n",
    "    PHI = NormDist.cdf(beta * sigma)\n",
    "    mu_metallicities = np.log(mean_metallicities / 2. / \n",
    "                              (np.exp(0.5 * sigma**2) * PHI))\n",
    "\n",
    "    # Create a range of metallicities (x-values or random variables)\n",
    "    log_metallicities = np.arange(min_logZ, max_logZ + step_logZ, step_logZ)\n",
    "    metallicities = np.exp(log_metallicities)\n",
    "\n",
    "    # Probabilities of log-skew-normal (without 1/Z factor)\n",
    "    dPdlogZ = (2. / sigma[:, np.newaxis] * \n",
    "               NormDist.pdf((log_metallicities - mu_metallicities[:, np.newaxis]) / sigma[:, np.newaxis]) * \n",
    "               NormDist.cdf(alpha * (log_metallicities - mu_metallicities[:, np.newaxis]) / sigma[:, np.newaxis]))\n",
    "\n",
    "    # Normalize distribution over all metallicities\n",
    "    norm = dPdlogZ.sum(axis=-1) * step_logZ\n",
    "    dPdlogZ = dPdlogZ / norm[:, np.newaxis]\n",
    "\n",
    "    # Flat-in-log distribution for sampled metallicity in COMPAS\n",
    "    p_draw_metallicity = 1 / (max_logZ_COMPAS - min_logZ_COMPAS)\n",
    "\n",
    "    return dPdlogZ, metallicities, p_draw_metallicity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.cosmology import WMAP9 as cosmo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_binaries = res\n",
    "redshifts = [0.1]\n",
    "times = cosmo.age(redshifts).to(u.yr).value\n",
    "time_first_SF = cosmo.age(10).to(u.yr).value\n",
    "n_formed = 10\n",
    "dPdlogZ = np.ones((1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frate, mrate = find_formation_and_merger_rates(\n",
    "    n_binaries=res,\n",
    "    redshifts=aa\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cher",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
